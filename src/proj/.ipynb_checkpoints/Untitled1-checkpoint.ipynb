{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c5d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings, random\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46003f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./open')\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b7feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna('NaN', inplace=True) \n",
    "test.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aea175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['family_size'] <= 7)]\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1bd53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)\n",
    "test.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f3e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d22d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "for feat in feats:\n",
    "    train[feat]=np.abs(train[feat])\n",
    "    test[feat]=np.abs(test[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88286ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    # before_EMPLOYED: 고용되기 전까지의 일수\n",
    "    df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "    df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "    df['before_EMPLOYED_m'] = np.floor(df['before_EMPLOYED'] / 30) - ((np.floor(df['before_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['before_EMPLOYED_w'] = np.floor(df['before_EMPLOYED'] / 7) - ((np.floor(df['before_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "    \n",
    "    #DAYS_BIRTH 파생변수- Age(나이), 태어난 월, 태어난 주(출생연도의 n주차)\n",
    "    df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "    df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) - ((np.floor(df['DAYS_BIRTH'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) - ((np.floor(df['DAYS_BIRTH'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    \n",
    "    #DAYS_EMPLOYED_m 파생변수- EMPLOYED(근속연수), DAYS_EMPLOYED_m(고용된 달) ,DAYS_EMPLOYED_w(고용된 주(고용연도의 n주차))  \n",
    "    df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "    df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) - ((np.floor(df['DAYS_EMPLOYED'] / 30) / 12).astype(int) * 12)\n",
    "    df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) - ((np.floor(df['DAYS_EMPLOYED'] / 7) / 4).astype(int) * 4)\n",
    "\n",
    "    #ability: 소득/(살아온 일수+ 근무일수)\n",
    "    df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "    \n",
    "    #income_mean: 소득/ 가족 수\n",
    "    df['income_mean'] = df['income_total'] / df['family_size']\n",
    "    \n",
    "    #ID 생성: 각 컬럼의 값들을 더해서 고유한 사람을 파악(*한 사람이 여러 개 카드를 만들 가능성을 고려해 begin_month는 제외함)\n",
    "    df['ID'] = \\\n",
    "    df['child_num'].astype(str) + '_' + df['income_total'].astype(str) + '_' +\\\n",
    "    df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' +\\\n",
    "    df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' +\\\n",
    "    df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' +\\\n",
    "    df['gender'].astype(str) + '_' + df['car'].astype(str) + '_' +\\\n",
    "    df['reality'].astype(str) + '_' + df['income_type'].astype(str) + '_' +\\\n",
    "    df['edu_type'].astype(str) + '_' + df['family_type'].astype(str) + '_' +\\\n",
    "    df['house_type'].astype(str) + '_' + df['occyp_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d11587b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED',]\n",
    "train.drop(cols, axis=1, inplace=True)\n",
    "test.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80bc0307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Numerical features:  18\n",
      "Number of Categorical features:  9\n"
     ]
    }
   ],
   "source": [
    "numerical_feats = train.dtypes[train.dtypes != \"object\"].index.tolist()\n",
    "numerical_feats.remove('credit')\n",
    "print(\"Number of Numerical features: \", len(numerical_feats))\n",
    "\n",
    "categorical_feats = train.dtypes[train.dtypes == \"object\"].index.tolist()\n",
    "print(\"Number of Categorical features: \", len(categorical_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5242e447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income_total',\n",
       " 'work_phone',\n",
       " 'phone',\n",
       " 'email',\n",
       " 'family_size',\n",
       " 'begin_month',\n",
       " 'before_EMPLOYED',\n",
       " 'income_total_befofeEMP_ratio',\n",
       " 'before_EMPLOYED_m',\n",
       " 'before_EMPLOYED_w',\n",
       " 'Age',\n",
       " 'DAYS_BIRTH_m',\n",
       " 'DAYS_BIRTH_w',\n",
       " 'EMPLOYED',\n",
       " 'DAYS_EMPLOYED_m',\n",
       " 'DAYS_EMPLOYED_w',\n",
       " 'ability',\n",
       " 'income_mean']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a977ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'car',\n",
       " 'reality',\n",
       " 'income_type',\n",
       " 'edu_type',\n",
       " 'family_type',\n",
       " 'house_type',\n",
       " 'occyp_type',\n",
       " 'ID']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0c987a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,test]:\n",
    "    df['income_total'] = np.log1p(1+df['income_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558140d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(categorical_feats)\n",
    "train[categorical_feats] = encoder.fit_transform(train[categorical_feats], train['credit'])\n",
    "test[categorical_feats] = encoder.transform(test[categorical_feats])\n",
    "\n",
    "train['ID'] = train['ID'].astype('int64')\n",
    "test['ID'] = test['ID'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81f1f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_train = train.drop(['credit'], axis=1)\n",
    "kmeans = KMeans(n_clusters=36, random_state=42).fit(kmeans_train)\n",
    "train['cluster'] = kmeans.predict(kmeans_train)\n",
    "test['cluster'] = kmeans.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "469a8401",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats.remove('income_total')\n",
    "scaler = StandardScaler()\n",
    "train[numerical_feats] = scaler.fit_transform(train[numerical_feats])\n",
    "test[numerical_feats] = scaler.transform(test[numerical_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e04a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=400 \n",
    "learning_rate=0.1\n",
    "max_depth=3\n",
    "n_est = 2000\n",
    "seed = 42\n",
    "n_fold = 15\n",
    "n_class = 3\n",
    "\n",
    "target = 'credit'\n",
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5322c38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- Fold 0 -----------------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_920\\2281796564.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m   \u001b[0mmodel_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m   \u001b[0mmodel_cat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[0mcat_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_cat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf_cpu\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'n_estimators'"
     ]
    }
   ],
   "source": [
    "skfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in skfold.split(X, y):\n",
    "        folds.append((train_idx, valid_idx))\n",
    "\n",
    "cat_pred = np.zeros((X.shape[0], n_class))\n",
    "cat_pred_test = np.zeros((X_test.shape[0], n_class))\n",
    "cat_cols = ['income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']\n",
    "for fold in range(n_fold):\n",
    "  print(f'\\n----------------- Fold {fold} -----------------\\n')\n",
    "  train_idx, valid_idx = folds[fold]\n",
    "    \n",
    "  X_train, X_valid, y_train, y_valid = X.iloc[train_idx], X.iloc[valid_idx], y[train_idx], y[valid_idx]\n",
    "  train_data = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "  valid_data = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "  model_cat = XGBClassifier()\n",
    "  model_cat.fit(train_data,valid_data, n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "  \n",
    "  cat_pred[valid_idx] = model_cat.predict_proba(X_valid)\n",
    "  cat_pred_test += model_cat.predict_proba(X_test) / n_fold\n",
    "  print(f'CV Log Loss Score: {log_loss(y_valid, cat_pred[valid_idx]):.6f}')\n",
    "    \n",
    "print(f'\\tLog Loss: {log_loss(y, cat_pred):.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfad75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(model_cat.get_feature_importance(),X_test.columns,'XGBOOST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29bd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2733b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.iloc[:, 1:] = cat_pred_test\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission0523_Final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86f96a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_cpu] *",
   "language": "python",
   "name": "conda-env-tf_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
